<?xml version="1.0" encoding="UTF-8"?>

<!--
 *
 * This help file was generated from detectSIFTFeatures.sci using help_from_sci().
 *
 -->

<refentry version="5.0-subset Scilab" xml:id="detectSIFTFeatures" xml:lang="en"
          xmlns="http://docbook.org/ns/docbook"
          xmlns:xlink="http://www.w3.org/1999/xlink"
          xmlns:svg="http://www.w3.org/2000/svg"
          xmlns:ns3="http://www.w3.org/1999/xhtml"
          xmlns:mml="http://www.w3.org/1998/Math/MathML"
          xmlns:scilab="http://www.scilab.org"
          xmlns:db="http://docbook.org/ns/docbook">

  <refnamediv>
    <refname>detectSIFTFeatures</refname>
    <refpurpose>This function is used to find scale-invariant features.</refpurpose>
  </refnamediv>


<refsynopsisdiv>
   <title>Calling Sequence</title>
   <synopsis>
   [ a ] = detectSIFTFeatures(srcImg)
   [ a ] = detectSIFTFeatures(srcImg, features, nOctaveLayers, contrastThreshold, edgeThreshold, sigma)
   
   </synopsis>
</refsynopsisdiv>

<refsection>
   <title>Parameters</title>
   <variablelist>
   <varlistentry><term>srcImg :</term>
      <listitem><para> Hyper of input image.</para></listitem></varlistentry>
   <varlistentry><term>nfeatures :</term>
      <listitem><para> The number of best features to retain. The features are ranked by their scores (measured in SIFT algorithm as the local contrast). If valued as 0, uses all detected keypoints.</para></listitem></varlistentry>
   <varlistentry><term>nOctaveLayers :</term>
      <listitem><para> The number of layers in each octave. 3 is the value used in D. Lowe paper. The number of octaves is computed automatically from the image resolution.</para></listitem></varlistentry>
   <varlistentry><term>contrastThreshold :</term>
      <listitem><para> The contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. The larger the threshold, the less features are produced by the detector.</para></listitem></varlistentry>
   <varlistentry><term>edgeThreshold :</term>
      <listitem><para> The threshold used to filter out edge-like features. Note that the its meaning is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are filtered out (more features are retained).</para></listitem></varlistentry>
   <varlistentry><term>sigma :</term>
      <listitem><para> The sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft lenses, you might want to reduce the number.</para></listitem></varlistentry>
   <varlistentry><term>a :</term>
      <listitem><para> It is a struct consisting of 'Type'(Type of Feature) , 'Features'(descriptors) , 'NumBits', 'NumFeatures', 'KeyPoints', 'keypointsCount'.</para></listitem></varlistentry>
   </variablelist>
</refsection>

<refsection>
   <title>Description</title>
   <para>
For extracting keypoints and computing descriptors using the Scale Invariant Feature Transform. RGB images are converted to Grayscale images before processing.
   </para>
   <para>
</para>
</refsection>

<refsection>
   <title>Examples</title>
   <programlisting role="example"><![CDATA[
// with default values
a = imread("photo1.jpeg");
b = imread("photo2.jpeg");
stacksize("max");
c = detectSIFTFeatures(a);
d = detectSIFTFeatures(b);
[ e f ] = matchFeatures(c.Features, d.Features);
out = drawMatch(a, b, c.KeyPoints, d.KeyPoints, e, f);

   ]]></programlisting>
</refsection>

<refsection>
   <title>Examples</title>
   <programlisting role="example"><![CDATA[
// user assigned values
a = imread("photo1.jpeg");
b = imread("photo2.jpeg");
stacksize("max");
c = detectSIFTFeatures(a, 0, 3, 0.05, 11, 1.6);
d = detectSIFTFeatures(b, 0, 3, 0.05, 11, 1.6);
[ e f ] = matchFeatures(c.Features, d.Features);
out = drawMatch(a, b, c.KeyPoints, d.KeyPoints, e, f);

   ]]></programlisting>
</refsection>

<refsection>
   <title>Authors</title>
   <simplelist type="vert">
   <member>Ashish Manatosh Barik, NIT Rourkela</member>
   </simplelist>
</refsection>
</refentry>
